{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import completeness_score, v_measure_score,normalized_mutual_info_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from code import utils,modeling\n",
    "import nltk,re,time,umap,collections\n",
    "from hdbscan import HDBSCAN\n",
    "from sentence_transformers import models\n",
    "from sklearn.preprocessing import normalize\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch import nn\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from  mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-german-cased\")\n",
    "%reload_ext utils\n",
    "%reload_ext modeling\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>seo_title</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at_date</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_uid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5ed1398149006b863542719239e660f51f2bfb43eae5954d5a26b0596cbb54ae</th>\n",
       "      <td>US Open: Als Alexander Zverev seinen Eltern da...</td>\n",
       "      <td>Als er seinen Eltern dankte, kamen ihm die Tränen</td>\n",
       "      <td>Was für ein Drama! Was für Emotionen! Alexande...</td>\n",
       "      <td>9/14/20</td>\n",
       "      <td>2020-09-14 11:56:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             headline  \\\n",
       "article_uid                                                                                             \n",
       "5ed1398149006b863542719239e660f51f2bfb43eae5954...  US Open: Als Alexander Zverev seinen Eltern da...   \n",
       "\n",
       "                                                                                            seo_title  \\\n",
       "article_uid                                                                                             \n",
       "5ed1398149006b863542719239e660f51f2bfb43eae5954...  Als er seinen Eltern dankte, kamen ihm die Tränen   \n",
       "\n",
       "                                                                                                 text  \\\n",
       "article_uid                                                                                             \n",
       "5ed1398149006b863542719239e660f51f2bfb43eae5954...  Was für ein Drama! Was für Emotionen! Alexande...   \n",
       "\n",
       "                                                   created_at_date  \\\n",
       "article_uid                                                          \n",
       "5ed1398149006b863542719239e660f51f2bfb43eae5954...         9/14/20   \n",
       "\n",
       "                                                            created_at  \n",
       "article_uid                                                             \n",
       "5ed1398149006b863542719239e660f51f2bfb43eae5954... 2020-09-14 11:56:15  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = utils.load_labeled_data()\n",
    "y= X[\"labels\"]\n",
    "X.drop([\"labels\",\"site\",\"entities_analyzed\",\"updated_at\"],inplace=True,axis=\"columns\")\n",
    "y_summarized_clusters = dict(collections.Counter(y))\n",
    "\n",
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiments = client.list_experiments() # returns a list of mlflow.entities.Experiment\n",
    "mlflow.set_experiment(\"TT - Clustering\")\n",
    "\n",
    "embeddings = modeling.get_sentence_embeddings(pdf)\n",
    "pdf = utils.preprocess_text(X,\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Reducing dimensionality from 1536 to 128 ...\n",
      ">> Clustering...\n",
      ">> --- Done in 3.6 seconds ---\n",
      "Outliers: 5 | Clustered: 234 | 0.9790794979079498 \n",
      " Cluster count: 18 \n",
      ">> Reducing dimensionality from 1536 to 128 ...\n",
      ">> Clustering...\n",
      ">> --- Done in 3.9 seconds ---\n",
      "Outliers: 1 | Clustered: 238 | 0.99581589958159 \n",
      " Cluster count: 14 \n",
      ">> Reducing dimensionality from 1536 to 256 ...\n",
      ">> Clustering...\n",
      ">> --- Done in 4.2 seconds ---\n",
      "Outliers: 1 | Clustered: 238 | 0.99581589958159 \n",
      " Cluster count: 14 \n",
      ">> Reducing dimensionality from 1536 to 256 ...\n",
      ">> Clustering...\n",
      ">> --- Done in 3.6 seconds ---\n",
      "Outliers: 4 | Clustered: 235 | 0.9832635983263598 \n",
      " Cluster count: 15 \n",
      ">> Reducing dimensionality from 1536 to 384 ...\n",
      ">> Clustering...\n",
      ">> --- Done in 3.7 seconds ---\n",
      "Outliers: 2 | Clustered: 237 | 0.9916317991631799 \n",
      " Cluster count: 15 \n",
      ">> Reducing dimensionality from 1536 to 384 ...\n",
      ">> Clustering...\n",
      ">> --- Done in 4.4 seconds ---\n",
      "Outliers: 2 | Clustered: 237 | 0.9916317991631799 \n",
      " Cluster count: 16 \n",
      ">> Reducing dimensionality from 1536 to 512 ...\n",
      ">> Clustering...\n",
      ">> --- Done in 3.9 seconds ---\n",
      "Outliers: 4 | Clustered: 235 | 0.9832635983263598 \n",
      " Cluster count: 15 \n",
      ">> Reducing dimensionality from 1536 to 512 ...\n",
      ">> Clustering...\n",
      ">> --- Done in 4.7 seconds ---\n",
      "Outliers: 4 | Clustered: 235 | 0.9832635983263598 \n",
      " Cluster count: 15 \n",
      ">> Reducing dimensionality from 1536 to 1024 ...\n",
      ">> Clustering...\n",
      ">> --- Done in 4.4 seconds ---\n",
      "Outliers: 223 | Clustered: 16 | 0.06694560669456066 \n",
      " Cluster count: 2 \n",
      ">> Reducing dimensionality from 1536 to 1024 ...\n",
      ">> Clustering...\n",
      ">> --- Done in 4.1 seconds ---\n",
      "Outliers: 223 | Clustered: 16 | 0.06694560669456066 \n",
      " Cluster count: 2 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "for N_COMPONENTS in [2,4,16,64,128,196,256,320,384,512,640]:\n",
    "    for min_cluster_size in range(2, 4):    \n",
    "        with mlflow.start_run():\n",
    "            #ctr=0\n",
    "\n",
    "            mlflow.log_param(key=\"min_cluster_size\",value=min_cluster_size)\n",
    "            mlflow.log_param(key=\"N_COMPONENTS\",value=N_COMPONENTS)            \n",
    "            results,cluster_labels = modeling.cluster_and_reduce(embeddings,n_components_clustering=N_COMPONENTS,min_cluster_size=min_cluster_size, min_samples= 3,alpha= 0.88)\n",
    "            mlflow.log_metric(key=\"completeness_score\", value=completeness_score(cluster_labels,y.values))\n",
    "            mlflow.log_metric(key=\"v_measure_score\", value=v_measure_score(cluster_labels,y.values))\n",
    "            mlflow.log_metric(key=\"normalized_mutual_info_score\", value=v_measure_score(cluster_labels,y.values))\n",
    "            mlflow.log_metric(key=\"normalized_mutual_info_score\", value=v_measure_score(cluster_labels,y.values))\n",
    "            \n",
    "            summarized_clusters = dict(collections.Counter(cluster_labels))\n",
    "            try:\n",
    "                mlflow.log_metric(key=\"outliers_ratio\", value=(summarized_clusters[-1]/len(cluster_labels)))\n",
    "            except Exception as err:\n",
    "                mlflow.log_metric(key=\"outliers_ratio\", value=0)\n",
    "\n",
    "            mlflow.log_metric(key=\"unique_cluters\", value=len(summarized_clusters.items()))\n",
    "            mlflow.log_metric(key=\"unique_cluters_ratio\", value=(len(summarized_clusters.items())-1)/len(y_summarized_clusters.items()))\n",
    "            results = utils.link_to_raw_data(results,X,cluster_labels)\n",
    "            \n",
    "            modeling.scatter_plot(results,save_fig=True)\n",
    "            mlflow.log_artifact(\"./tmp_scatter_plot.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01704bfbaba642cdb6d22578462ce16f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batches', max=8.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Embedding dimension 1536\n",
      "--- 239 Documnets encoded 37.68475890159607 seconds ---\n",
      ">> Reducing dimensionality from 1536 to 500 ...\n",
      ">> Clustering...\n",
      ">> --- Done in 10.7 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.921907445792243, 0.8348861954499294)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results,cluster_labels = modeling.cluster_and_reduce(embeddings,n_components_clustering=500,\n",
    "                                                     min_cluster_size=2, min_samples= 3,alpha= 0.88)\n",
    "completeness_score(cluster_labels,y.values), v_measure_score(cluster_labels,y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
